{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Pandas Library**\n",
        "\n",
        "Pandas is a powerful Python library used for data manipulation and analysis. It provides easy-to-use tools for working with structured data (like tables) efficiently.\n",
        "\n",
        "### **Why Use Pandas?**\n",
        "\n",
        "**1. Easy Data Handling**\n",
        "\n",
        "Pandas lets you work with spreadsheet-like data (rows & columns) in Python.\n",
        "\n",
        "You can load data from CSV, Excel, SQL databases, JSON, and more.\n",
        "\n",
        "**2. Data Cleaning Made Simple**\n",
        "\n",
        "Fix missing or incorrect data easily.\n",
        "\n",
        "Remove duplicates, filter rows, and modify columns effortlessly.\n",
        "\n",
        "**3. Powerful Data Analysis**\n",
        "\n",
        "Calculate statistics (mean, median, max, min, etc.) in one line.\n",
        "\n",
        "Group, sort, and filter data quickly.\n",
        "\n",
        "**4. Works Well with Other Libraries**\n",
        "\n",
        "Pandas integrates with Matplotlib/Seaborn (for plotting), Scikit-learn (for machine learning), and more.\n",
        "\n",
        "**5. Fast & Efficient**\n",
        "\n",
        "Optimized for performance (much faster than pure Python for large datasets).\n",
        "\n",
        "\n",
        "## **Data Structure in Pandas**\n",
        "\n",
        "Pandas has two main data structures: Series (1D) and DataFrame (2D). They are the building blocks for data manipulation in Python.\n",
        "\n",
        "**1. Series - 1D Data (Like a Single Column)**\n",
        "A Series is like a single column in Excel or a list with labels (index).\n",
        "\n",
        "**Key Features:**\n",
        "\n",
        "- Holds one type of data (int, float, string, etc.)\n",
        "\n",
        "- Has an index (row labels)\n",
        "\n",
        "- Behaves like a NumPy array but with labels"
      ],
      "metadata": {
        "id": "a7rC_bEpc_Ct"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVowD9AicNdy",
        "outputId": "412e0dfb-f411-45cb-c2a4-58cf48d80a32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    10\n",
            "1    20\n",
            "2    30\n",
            "3    40\n",
            "4    50\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd # importing pandas and using an alias as pd\n",
        "\n",
        "# creating series from list (default index: 0, 1, 2...)\n",
        "a = pd.Series([10, 20, 30, 40, 50])\n",
        "print(a)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating series by specifying custom index\n",
        "\n",
        "a = pd.Series([10, 20, 30, 40, 50], index=[\"A\", \"B\", \"C\",\"D\", \"E\"]) #specifying index for each item\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rkn1TVMhhnQ",
        "outputId": "3d90a49d-8d21-4008-dfc9-205f78370f92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A    10\n",
            "B    20\n",
            "C    30\n",
            "D    40\n",
            "E    50\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. DataFrames in Pandas - 2D Data**\n",
        "\n",
        "A DataFrame is a table with rows and columns (like an Excel sheet or SQL table).\n",
        "\n",
        "**Key Features:**\n",
        "\n",
        "- Made up of multiple Series (columns)\n",
        "\n",
        "- Each column can have a different data type\n",
        "\n",
        "- Has row index and column names"
      ],
      "metadata": {
        "id": "bMpU9g-mh7Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary named 'data' with three keys: \"Name\", \"Age\", and \"City\".\n",
        "# Each key maps to a list of values.\n",
        "data = {\n",
        "    \"Name\": [\"ABC\", \"DEF\", \"XYZ\"], # List of names\n",
        "    \"Age\": [25, 30, 35],           # Corresponding ages for each person\n",
        "    \"City\": [\"Pune\", \"Mumbai\", \"Delhi\"] # Corresponding cities for each person\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data) ## Creating a DataFrame 'df' from the dictionary 'data', using the method pd.DataFrame\n",
        "print(df) # Printing the dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adExlZEgiU8f",
        "outputId": "ecde3569-69d0-44b6-db8d-2e331ba46905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Name  Age    City\n",
            "0  ABC   25    Pune\n",
            "1  DEF   30  Mumbai\n",
            "2  XYZ   35   Delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#custom index\n",
        "df = pd.DataFrame(data, index=[\"P1\", \"P2\", \"P3\"])\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBPtZxyEjaYt",
        "outputId": "c61cbd75-5aec-4d60-b35c-3dc4258aebd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Name  Age    City\n",
            "P1  ABC   25    Pune\n",
            "P2  DEF   30  Mumbai\n",
            "P3  XYZ   35   Delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Types in Pandas**\n",
        "\n",
        "In Pandas, data types (also called dtypes) define what kind of data is stored in each column of a DataFrame or Series. Choosing the right data type helps save memory and improves performance.\n",
        "\n",
        "**Common Pandas Data Types**\n",
        "\n",
        "| Pandas dtype     | Python Equivalent | Description                                 |\n",
        "|------------------|-------------------|---------------------------------------------|\n",
        "| `int64`          | `int`             | Integer numbers (e.g., 5, -3, 100)          |\n",
        "| `float64`        | `float`           | Decimal numbers (e.g., 3.14, -0.5)          |\n",
        "| `object`         | `str`             | Text (strings) or mixed data types          |\n",
        "| `bool`           | `bool`            | True or False                               |\n",
        "| `datetime64`     | `datetime`        | Date and time (e.g., \"2023-10-05\")          |\n",
        "| `category`       | -                 | Limited unique values (e.g., \"Male\", \"Female\") |\n",
        "| `timedelta[ns]`  | -                 | Time differences (e.g., \"5 days\")           |\n",
        "\n",
        "\n",
        "### **Why Are Data Types Important?**\n",
        "\n",
        "- **Memory Efficiency**\n",
        "\n",
        "Using int32 instead of int64 saves memory for large datasets.\n",
        "\n",
        "category dtype reduces memory for repetitive text (e.g., gender, country).\n",
        "\n",
        "- **Performance**\n",
        "\n",
        "Numerical operations (int, float) are faster than strings (object).\n",
        "\n",
        "- **Correct Operations**\n",
        "\n",
        "You canâ€™t do math on strings (object dtype).\n",
        "\n",
        "Dates (datetime64) allow time-based calculations.\n",
        "\n"
      ],
      "metadata": {
        "id": "iMWCpl5Hjrt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes # checks and returns the datatype for each column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "ayrmrdrvjrUh",
        "outputId": "b3e6a4a2-37a1-4da3-a036-f37f11d64d24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Name    object\n",
              "Age      int64\n",
              "City    object\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Name</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Age</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>City</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    \"Name\": [\"ABC\", \"DEF\", \"XYZ\"],  # object (string)\n",
        "    \"Age\": [25, 30, 35],                 # int64\n",
        "    \"Salary\": [50000.0, 60000.5, 70000.0],  # float64\n",
        "    \"Employed\": [True, False, True],      # bool\n",
        "    \"Gender\": [\"Male\", \"Female\", \"Male\"], # Object(string)\n",
        "    \"Join_Date\": pd.to_datetime([\"2020-01-01\", \"2019-05-15\", \"2021-11-20\"])  # datetime64\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyFXY4ABlmUK",
        "outputId": "72b03f89-669d-4256-e25d-0fac8d1bfa6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name                 object\n",
            "Age                   int64\n",
            "Salary              float64\n",
            "Employed               bool\n",
            "Gender               object\n",
            "Join_Date    datetime64[ns]\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To change the datatype in pandas for any column use astype() it converts a column to a different specified dtype.**\n",
        "\n"
      ],
      "metadata": {
        "id": "TsPwgn1FnHH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Age\"] = df[\"Age\"].astype(\"float64\")  # Converts Age to float\n",
        "df[\"Employed\"] = df[\"Employed\"].astype(\"int\")  # Converts bool to int (1 or 0)"
      ],
      "metadata": {
        "id": "TBdXEKMQnC4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Join_Date\"] = pd.to_datetime(df[\"Join_Date\"]) # For converting datetime"
      ],
      "metadata": {
        "id": "IYtKUoB7nrCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Gender\"] = df[\"Gender\"].astype(\"category\") # For converting categorical columns"
      ],
      "metadata": {
        "id": "qUKk7ycInrwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df) # changes after converting the datatype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9bT_57qng93",
        "outputId": "877d90c5-2edd-4125-c2d8-8642fc941af0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Name   Age   Salary  Employed  Gender  Join_Date\n",
            "0  ABC  25.0  50000.0         1    Male 2020-01-01\n",
            "1  DEF  30.0  60000.5         0  Female 2019-05-15\n",
            "2  XYZ  35.0  70000.0         1    Male 2021-11-20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Pandas automatically assigns data types when loading data.**\n",
        "\n",
        "- **Use df.dtypes to check column types.**\n",
        "\n",
        "- **Convert types with astype() for better performance.**\n",
        "\n",
        "- **Use category for repetitive text, datetime64 for dates, and numerical types (int, float) for calculations.**"
      ],
      "metadata": {
        "id": "EE7aXWrQoSrR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading Data in Pandas**\n",
        "\n",
        "Pandas provides powerful methods ,functions to read data from various sources.\n",
        "\n",
        "**1. Reading from CSV files**\n",
        "```\n",
        "pd.read_csv('data.csv')  # Basic CSV read\n",
        "pd.read_csv('data.csv', sep=';')  # Custom delimiter\n",
        "pd.read_csv('data.csv', header=None)  # No header row\n",
        "pd.read_csv('data.csv', names=['col1','col2'])  # Custom column names\n",
        "pd.read_csv('data.csv', index_col='date')  # Set index column\n",
        "pd.read_csv('data.csv', skiprows=5)   # Skip first 5 rows\n",
        "pd.read_csv('data.csv', na_values=['NA','missing'])  # Custom NA values\n",
        "\n",
        "```\n",
        "\n",
        "**2. Reading from Excel files**\n",
        "\n",
        "```\n",
        "pd.read_excel('data.xlsx')  # Read first sheet\n",
        "pd.read_excel('data.xlsx', sheet_name='Sheet2')  # Specific sheet\n",
        "pd.read_excel('data.xlsx', sheet_name=[0,1])  # Multiple sheets (returns dict)\n",
        "pd.read_excel('data.xlsx', usecols='A:C')  # Read specific columns\n",
        "\n",
        "```\n",
        "\n",
        "**3. Reading from Text files**\n",
        "\n",
        "```\n",
        "pd.read_table('data.txt')  # Tab-delimited (like CSV)\n",
        "pd.read_fwf('data.txt')  # Fixed-width format\n",
        "```\n",
        "\n",
        "**4.Reading Data from SQL Database**\n",
        "\n",
        "```\n",
        "import sqlite3\n",
        "conn = sqlite3.connect('database.db')\n",
        "\n",
        "# Using SQLAlchemy (recommended for production)\n",
        "from sqlalchemy import create_engine\n",
        "engine = create_engine('postgresql://user:pass@localhost:5432/db') #add your username and password\n",
        "\n",
        "pd.read_sql('SELECT * FROM table', con=conn)\n",
        "pd.read_sql_table('table_name', con=engine)\n",
        "pd.read_sql_query('SELECT col1, col2 FROM table', con=conn)\n",
        "```\n",
        "\n",
        "**5.Reading Data from HTML tables**\n",
        "\n",
        "```\n",
        "pd.read_html('https://example.com/tables.html')  # Returns list of DataFrames\n",
        "```\n",
        "\n",
        "**6. Reading from JSON Data**\n",
        "\n",
        "```\n",
        "pd.read_json('data.json')\n",
        "pd.json_normalize(nested_json)  # For nested JSON\n",
        "```\n",
        "\n",
        "**7.Reading from API'S**\n",
        "\n",
        "```\n",
        "import requests\n",
        "data = requests.get('https://api.example.com/data').json()\n",
        "df = pd.DataFrame(data)\n",
        "```\n",
        "\n",
        "**8.Reading data from Clipboard**\n",
        "\n",
        "```\n",
        "df = pd.read_clipboard()  # Great for quick testing\n",
        "```"
      ],
      "metadata": {
        "id": "ayaZ-wlI0iAP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Inspection Methods in Pandas**\n",
        "\n",
        "1. **head()**\n",
        "```\n",
        "df.head()\n",
        "```\n",
        "- Returns the first 5 rows of the DataFrame by default. Useful for a quick look at the data.\n",
        "\n",
        "2. **tail()**\n",
        "```\n",
        "df.tail()\n",
        "```\n",
        "- Returns the last 5 rows of the DataFrame. Useful for inspecting the end of the dataset.\n",
        "\n",
        "3. **shape**\n",
        "```\n",
        "df.shape\n",
        "```\n",
        "Returns a tuple (rows, columns) indicating the number of rows and columns in the DataFrame.\n",
        "\n",
        "4. **info()**\n",
        "```\n",
        "df.info()\n",
        "```\n",
        "\n",
        "Displays a concise summary of the DataFrame, including:\n",
        "\n",
        "- Number of non-null entries\n",
        "\n",
        "- Data types of each column\n",
        "\n",
        "- Memory usage\n",
        "\n",
        "5. **describe()**\n",
        "```\n",
        "df.describe()\n",
        "```\n",
        "Provides a statistical summary of numerical columns, including:\n",
        "\n",
        "- Count\n",
        "\n",
        "- Mean\n",
        "\n",
        "- Standard deviation\n",
        "\n",
        "- Min/Max\n",
        "\n",
        "- 25th, 50th (median), and 75th percentiles\n",
        "\n",
        "6. **dtypes**\n",
        "```\n",
        "df.dtypes\n",
        "```\n",
        "\n",
        "- Shows the data type of each column in the DataFrame (e.g., int64, object, float64).\n",
        "\n",
        "7.**columns**\n",
        "```\n",
        "df.columns\n",
        "```\n",
        "\n",
        "- Returns an Index object containing the names of all columns in the DataFrame.\n",
        "\n",
        "8. **index**\n",
        "```\n",
        "df.index\n",
        "```\n",
        "- Returns the index (row labels) of the DataFrame.\n",
        "\n",
        "9. **isnull()**\n",
        "```\n",
        "df.isnull()\n",
        "```\n",
        "- Returns a DataFrame of the same shape as df, with True for missing values (NaN) and False otherwise.\n",
        "\n",
        "10. **isnull().sum()**\n",
        "```\n",
        "df.isnull().sum()\n",
        "```\n",
        "- Returns total number of missing values in each column\n",
        "\n",
        "11. **duplicated()**\n",
        "```\n",
        "df.duplicated()\n",
        "```\n",
        "- Returns a boolean Series indicating whether each row is a duplicate of a previous row.\n",
        "\n",
        "12. **duplicated().sum()**\n",
        "```\n",
        "df.duplicated().sum()\n",
        "```\n",
        "- Returns the total number of duplicate rows.\n",
        "\n",
        "13. **nunique()**\n",
        "```\n",
        "df.nunique()\n",
        "```\n",
        "\n",
        "- Returns the number of unique values per column.\n",
        "\n",
        "14. **value_counts()**\n",
        "```\n",
        "df.value_counts()\n",
        "```\n",
        "- Returns value counts for a Series (not DataFrame) â€” useful on a single column.\n",
        "\n",
        "15. **columns.tolist()**\n",
        "```\n",
        "df.columns.tolist()\n",
        "```\n",
        "- Converts the Index of column names to a Python list.\n",
        "\n",
        "16. **index.tolist()**\t  \n",
        "```\n",
        "df.index.tolist()\n",
        "```\n",
        "- Converts the Index of row labels to a list.\n",
        "\n",
        "17. **empty**\n",
        "```\n",
        "df.empty\n",
        "```\n",
        "- Returns True if the DataFrame is empty (no rows or columns).\n",
        "\n",
        "18. **sample()**\n",
        "```\n",
        "df.sample(n)\n",
        "```\n",
        "- Randomly selects n rows from the DataFrame. Good for spot-checking data.\n"
      ],
      "metadata": {
        "id": "DD2E59GwpIZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Selection Methods**\n",
        "\n",
        "Data Selection is critical part of data analysis and manipulation. We can easily acheive this using pandas library.\n",
        "\n",
        "19. **Fetch one column**\n",
        "```\n",
        "df['column name']\n",
        "```\n",
        "- Returns the column specified in the form of series\n",
        "\n",
        "20. **Fetch Multiple Columns**\n",
        "```\n",
        "df['column1','column2']\n",
        "```\n",
        "- Returns multiple specified columns in the form of dataframe.\n",
        "\n",
        "30. **iloc**\n",
        "```\n",
        "df.iloc['row_label']\n",
        "df.iloc['row_index, column_index']\n",
        "```\n",
        "\n",
        "- Returns the row as per the specified row index.\n",
        "\n",
        "31. **loc**\n",
        "\n",
        "```\n",
        "df.loc['row_label']\n",
        "df.loc['row_label, 'column_name'']\n",
        "```\n",
        "- Returns the rows/columns as per the specified labels.\n",
        "\n",
        "32. **at**\n",
        "\n",
        "```\n",
        "df.at[row_label, 'column_name']\n",
        "```\n",
        "- Returns a single specified cell based on the specified row label, and column name.\n",
        "\n",
        "\n",
        "33. **iat**\n",
        "\n",
        "```\n",
        "df.iat[row_index, column_index]\n",
        "```\n",
        "\n",
        "- Returns a single specified cell based on specified row and column index\n",
        "\n",
        "\n",
        "34. **get()**\n",
        "\n",
        "```\n",
        "df.get(key, default=None)\n",
        "key: The column name you want.\n",
        "\n",
        "default: Value to return if the column is not found. (Default is None)\n",
        "```\n",
        "- It's similar to **df['column_name']**, but it wonâ€™t give an error if the column doesnâ€™t exist â€” it just returns None (or whatever default you provide).\n",
        "\n",
        "35. **filter()**\n",
        "```\n",
        "df.filter(items=None, like=None, regex=None, axis=None)\n",
        "items:\tList of names to keep\n",
        "like:\tSubstring to match in labels (e.g. all columns with 'age' in the name)\n",
        "regex:\tRegular expression pattern to match labels\n",
        "axis:\tAxis to filter on: 0 = rows, 1 = columns (default is 1)\n",
        "```\n",
        "- It is used to select specific rows or columns from a DataFrame by names or patterns.\n",
        "\n",
        "36. **xs()**\n",
        "\n",
        "\n",
        "```\n",
        "df.xs(key, axis=0, level=None, drop_level=True)\n",
        "\n",
        "key: The label you want to select\n",
        "axis: 0 = rows (default), 1 = columns\n",
        "level: The name or number of the level you want to select from\n",
        "drop_level: Whether to drop the selected level from the result (default is True)\n",
        "\n",
        "```\n",
        "\n",
        "- It is used to select data at a particular level from a MultiIndex DataFrame (DataFrames with more than one index level).\n",
        "\n",
        "37. **query()**\n",
        "\n",
        "```\n",
        "df.query()\n",
        "\n",
        "```\n",
        "\n",
        "- It lets you filter rows in a DataFrame using a string expression, similar to SQL.Features you can use inside query(), are Numeric filters, string filters, multiple conditions, variables.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Wg7vQZNh0nj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  **Data Cleaning Methods**\n",
        "\n",
        "Data cleaning means fixing or removing incorrect, missing, or unwanted data in your DataFrame.\n",
        "It helps make your data accurate and ready for analysis.\n",
        "\n",
        "38. **dropna()**\n",
        "```\n",
        "df.dropna()\n",
        "```\n",
        "- Drops rows with missing values.\n",
        "\n",
        "39. **dropna() - for columns**\n",
        "```\n",
        "df.dropna(axis=1)\n",
        "```\n",
        "- Drops columns with missing values.\n",
        "\n",
        "40. **fillna()**\n",
        "\n",
        "```\n",
        "df.fillna(0)\n",
        "```\n",
        "- Fills the missing values with 0\n",
        "\n",
        "41. **fillna() - forward fill**\n",
        "```\n",
        "df.fillna(method='ffill', inplace=True)\n",
        "```\n",
        "- Fills missing values with the value from the previous row.\n",
        "\n",
        "42. **fillna() - Backward fill**\n",
        "```\n",
        "df.fillna(method='bfill', inplace=True)\n",
        "```\n",
        "- Fills missing values with the value from the next row.\n",
        "\n",
        "43. **fillna() - using mean**\n",
        "```\n",
        "df['column_name'] = df['column_name'].fillna(df['column_name'].mean())\n",
        "```\n",
        "- Fills missing values with the column mean\n",
        "\n",
        "44. **fillna() - using median**\n",
        "```\n",
        "df['column_name'] = df['column_name'].fillna(df['column_name'].median())\n",
        "```\n",
        "- Fills missing values with the column median\n",
        "\n",
        "45. **fillna() - using mode**\n",
        "```\n",
        "df['column_name'] = df['column_name'].fillna(df['column_name'].mode()[0])\n",
        "```\n",
        "- Fills missing values with the column median\n",
        "* mode() returns a Series. Use [0] to get the most frequent value.\n",
        "\n",
        "46. **fillna - different values/methods for different columns**\n",
        "```\n",
        "df.fillna({\n",
        "    'column1': value_or_method1,\n",
        "    'column2': value_or_method2,\n",
        "    ...\n",
        "}, inplace=True)\n",
        "```\n",
        "- fills missing values with different values for different columns.\n",
        "\n",
        "47. **replace()**\n",
        "```\n",
        "df['column'].replace({old_value: new_value, ...}, inplace=True)\n",
        "```\n",
        "- Replaces values in the selected column according to the provided dictionary. The keys of the dictionary represent the values to be replaced (old_value), and the dictionary values are the replacement values (new_value).\n",
        "\n",
        "48. **rename()**\n",
        "```\n",
        "df.rename(columns={'old_name': 'new_name'}, inplace=True)\n",
        "```\n",
        "- Renames the column name with the specified new name.\n",
        "\n",
        "49. **reset_index()**\n",
        "```\n",
        "df.reset_index(level=None, drop=False, inplace=False)\n",
        "level: Resets a specific level if MultiIndex. (Optional)\n",
        "drop: True = remove index (donâ€™t add it as a column)\n",
        "False = add index as a column\n",
        "inplace: True = modify the original DataFrame\n",
        "False = return a new DataFrame\n",
        "```\n",
        "\n",
        "- It is used to reset the index of a DataFrame back to the default integer index\n",
        "\n",
        "50. **str.strip()**\n",
        "\n",
        "```\n",
        "df['column'] = df['column'].str.strip()\n",
        "```\n",
        "\n",
        "- Removes Leading/Trailing Spaces in Strings.\n",
        "\n",
        "51. **notnull()**\n",
        "```\n",
        "df = df[df['column'].notnull()]\n",
        "```\n",
        "- Drops rows with incorrect data\n",
        "\n",
        "52. **str.lower()/str.upper()**\n",
        "```\n",
        "df['column'] = df['column'].str.lower()\n",
        "df['column'] = df['column'].str.upper()\n",
        "```\n",
        "- Converts text in a column to lowercase or uppercase\n",
        "\n",
        "**Handling Outliers in Pandas**\n",
        "\n",
        "53. **Simple filtering using threshold**\n",
        "```\n",
        "df = df[df['column'] < upper_limit]\n",
        "df = df[df['column'] > lower_limit]\n",
        "```\n",
        "- Remove values beyond a fixed limit.\n",
        "\n",
        "54.  **Using IQR - Interquartile Range Method**\n",
        "```\n",
        "Q1 = df['column'].quantile(0.25)\n",
        "Q3 = df['column'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower = Q1 - 1.5 * IQR\n",
        "upper = Q3 + 1.5 * IQR\n",
        "df = df[(df['column'] >= lower) & (df['column'] <= upper)]\n",
        "```\n",
        "- Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
        "\n",
        "- Compute IQR = Q3 - Q1\n",
        "\n",
        "- Define outlier range:\n",
        "\n",
        "  - Lower bound = Q1 - 1.5 Ã— IQR\n",
        "\n",
        "  - Upper bound = Q3 + 1.5 Ã— IQR\n",
        "\n",
        "- Remove rows outside this range.\n",
        "\n"
      ],
      "metadata": {
        "id": "XS9p644xZrG6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Transformation Methods**\n",
        "\n",
        "55. **map()**\n",
        "```\n",
        "df['column'].map(function_or_dict)\n",
        "```\n",
        "- It is used to map or transform values in a single column or Series.\n",
        "\n",
        "56. **apply()**\n",
        "```\n",
        "df['column'].apply(func) # On Series\n",
        "# On DataFrame\n",
        "df.apply(func, axis=0)   # column-wise\n",
        "df.apply(func, axis=1)   # row-wise\n",
        "```\n",
        "\n",
        "- It is used to apply a function row-wise or column-wise in DataFrame\n",
        "Or to a single Series.\n",
        "\n",
        "57. **applymap()**\n",
        "```\n",
        "df.applymap(function)\n",
        "```\n",
        "- It is used to apply a function to each element of a DataFrame (not Series).\n",
        "\n",
        "58. **sort_values()**\n",
        "```\n",
        "df.sort_values(by='column_name', ascending=True)\n",
        "by: Column name(s) to sort by\n",
        "ascending: True = ascending order (default), False = descending\n",
        "inplace: True to modify the original DataFrame\n",
        "```\n",
        "\n",
        "- It sorts the DataFrame by column values\n",
        "\n",
        "59. **sort_index()**\n",
        "```\n",
        "df.sort_index(axis=0, ascending=True)\n",
        "axis=0 â†’ sort by row index\n",
        "axis=1 â†’ sort by column names\n",
        "ascending: default is True\n",
        "```\n",
        "- Sorts the DataFrame by row or column index\n",
        "\n",
        "60. **groupby()**\n",
        "```\n",
        "df.groupby('col').sum()\n",
        "df.groupby(['col1', 'col2'])['val'].agg(['mean', 'max'])\n",
        "```\n",
        "- The groupby() method takes one or more column names as arguments, which are used to group the DataFrame.\n",
        "- After grouping, you can apply various functions to each group.\n",
        "- Common aggregation functions include sum(), mean(), median(), count(), min(), max(), and std().\n",
        "\n",
        "61. **concat()**\n",
        "```\n",
        "pd.concat([df1, df2], axis=0)  # row-wise (default)\n",
        "pd.concat([df1, df2], axis=1)  # column-wise\n",
        "```\n",
        "- Stack DataFrames vertically or horizontally\n",
        "- Combining columns from different DataFrames, and Appending rows to existing DataFrames.\n",
        "\n",
        "62. **merge()**\n",
        "```\n",
        "pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None)\n",
        "left, right: The two DataFrames to merge.\n",
        "on: Column name(s) to join on (must be present in both DataFrames).\n",
        "left_on, right_on: Use when joining on columns with different names in each DataFrame.\n",
        "how: Type of join: 'inner', 'outer', 'left', 'right'.\n",
        "suffixes: Suffixes to apply to overlapping column names.\n",
        "```\n",
        "- It is used to combine two DataFrames based on common columns or indexes, similar to SQL joins.\n",
        "\n",
        "63. **join()**\n",
        "```\n",
        "df1.join(df2, how='left', on=None, lsuffix='', rsuffix='', sort=False)\n",
        "other: The DataFrame to join with (the one to add columns from)\n",
        "on: Column(s) in the calling DataFrame to join on instead of the index. Both\n",
        "DataFrames must have those columns if set.\n",
        "how: Type of join: 'left' (default), 'right', 'outer', or 'inner'\n",
        "lsuffix: Suffix to add to overlapping column names in the calling DataFrame\n",
        "rsuffix: Suffix to add to overlapping column names in the other DataFrame\n",
        "sort: Whether to sort the join keys lexicographically (default False)\n",
        "```\n",
        "- It is used to combine two DataFrames based on their index (or optionally on a column). Itâ€™s similar to SQL joins but is optimized for index-based merging.\n",
        "\n",
        "64. **append()**\n",
        "```\n",
        "df1.append(df2, ignore_index=False, verify_integrity=False, sort=False)\n",
        "df2: DataFrame or Series to append to df1\n",
        "ignore_index: If True, the resulting DataFrame will have a new integer index (default is False)\n",
        "verify_integrity: If True, checks for duplicate indices and raises an error if found\n",
        "sort: Sort columns if columns donâ€™t match (default is False)\n",
        "```\n",
        "- append() is used to add rows of one DataFrame to the end of another DataFrame.\n",
        "- Itâ€™s similar to concatenating two DataFrames vertically.\n",
        "- It does not modify the original DataFrame but returns a new DataFrame.\n",
        "\n",
        "65. **pivot()**\n",
        "```\n",
        "df.pivot(index='row_column', columns='column_column', values='value_column')\n",
        "index: Column to use for row labels in the new table\n",
        "columns: Column whose unique values become the new columns\n",
        "values: Column to fill the cell values of the new table\n",
        "```\n",
        "- The pivot() function reshapes the DataFrame from long format to wide format by turning unique values from one column into columns.\n",
        "- All combinations of index and columns must be unique.\n",
        "  - If not, pivot() will raise a ValueError.\n",
        "- To handle duplicates, use pivot_table() instead (it allows aggregation).\n",
        "\n",
        "66. **melt()**\n",
        "```\n",
        "pd.melt(frame, id_vars=None, value_vars=None, var_name=None, value_name='value', col_level=None, ignore_index=True)\n",
        "frame: The DataFrame to melt\n",
        "id_vars: Columns to keep as identifier variables (stay in each row)\n",
        "value_vars: Columns to unpivot (melt); if None, all other columns are used\n",
        "var_name: Name for the 'variable' column (formerly column names)\n",
        "value_name: Name for the 'value' column\n",
        "ignore_index: If False, retains the original index\n",
        "```\n",
        "- The melt() function unpivots a DataFrame from wide format to long format, turning columns into rows.\n",
        "\n",
        "- It is used when you want to normalize your data for analysis or visualization.\n",
        "\n",
        "#### **Binning (Discretizing values)**\n",
        "\n",
        "**Binning is the process of grouping continuous numeric data into discrete intervals (or \"bins\"). It helps simplify data and uncover patterns by categorizing values â€” for example, grouping ages into \"child\", \"adult\", \"senior\".**\n",
        "\n",
        "67. **pd.cut**\n",
        "```\n",
        "pd.cut(x, bins, labels=None, right=True, include_lowest=False)\n",
        "```\n",
        "- cut() is used to segment and sort numeric values into fixed intervals (equal width or custom-defined).\n",
        "\n",
        "68. **pd.qcut()**\n",
        "\n",
        "```\n",
        "pd.qcut(x, q, labels=None, precision=3, duplicates='raise')\n",
        "```\n",
        "- qcut() is used to divide data into equal-sized quantile bins based on the distribution.\n",
        "\n",
        "#### **Encoding**\n",
        "\n",
        "Encoding is the process of converting categorical data (like strings or labels) into a numerical format that can be used in analysis or machine learning models.\n",
        "\n",
        "\n",
        "69. **Label Encoding**\n",
        "\n",
        "```\n",
        "df['column_name'] = df['column_name'].astype('category').cat.codes\n",
        "```\n",
        "- Label Encoding assigns a unique integer to each category in a column.\n",
        "  - Best for: Ordinal data (where order matters).\n",
        "\n",
        "70. **One-Hot Encoding**  \n",
        "\n",
        "```\n",
        "pd.get_dummies(df, columns=['column_name'])\n",
        "```\n",
        "\n",
        "-One-Hot Encoding converts each category into a separate binary column (0 or 1).\n",
        " - Best for: Nominal data (no natural order).\n",
        "\n",
        "# **String Methods in Pandas**\n",
        "\n",
        " 71. **lower()**\n",
        "\n",
        " ```\n",
        " df['column'].str.lower()\n",
        " ```\n",
        " - Converts the text in the column to lower case.\n",
        "\n",
        " 72. **upper()**\n",
        "\n",
        " ```\n",
        " df['column'].str.upper()\n",
        " ```\n",
        " - Converts the text in the column to upper case.\n",
        "\n",
        " 73. **title()**\n",
        "\n",
        " ```\n",
        " df['column'].str.title()\n",
        " ```\n",
        " - Capitalizes first letter of each word\n",
        "\n",
        " 74. **strip()**\n",
        "\n",
        " ```\n",
        "  df['column'].str.strip()\n",
        " ```\n",
        "\n",
        " - Removes leading/trailing spaces\n",
        "\n",
        " 75. **replace()**\n",
        "\n",
        " ```\n",
        " df['column'].str.replace(a,b)\n",
        " ```\n",
        " - Replaces substring\n",
        "\n",
        " 76.  **contains()**\n",
        "\n",
        " ```\n",
        " df['column'].str.contains(x)\n",
        "```\n",
        "- It searches for a specified substring or regular expression within each string element of a Series.\n",
        "\n",
        "77. **startswith('x')**\n",
        "\n",
        "```\n",
        " df['column'].str.startswith('x')\n",
        "```\n",
        "- Checks if the string starts with the specified value, if yes it returns true.\n",
        "\n",
        "78. **endswith('x')**\n",
        "\n",
        "```\n",
        " df['column'].str.endswith('x')\n",
        "```\n",
        "- Checks if the string ends with the specified value, if yes it returns true.\n",
        "\n",
        "79. **len()**\n",
        "\n",
        "```\n",
        " df['column'].str.len()\n",
        "```\n",
        "- Returns length of each string.\n",
        "\n",
        "80. **splits()**\n",
        "\n",
        "```\n",
        "df['column'].str.split(' ')\n",
        "```\n",
        "- Splits string on the specified delimiter.\n",
        "\n",
        "81. **get(n)**\n",
        "\n",
        "```\n",
        "df['column'].str.get(n)\n",
        "```\n",
        "- Extracts an element from a list or string-like structure at a specific index n.\n",
        "\n",
        "82. **extract(r 'regex')**\n",
        "\n",
        "```\n",
        "df['column'].str.extract(r'regex_pattern')\n",
        "```\n",
        "- Extracts specific substrings from a string column using regular expressions (regex). Like extracting domain name from email address. It's useful when you want to pull structured data out of unstructured text.\n",
        "\n",
        "83. **extractall()**\n",
        "\n",
        "```\n",
        "df['column'].str.extractall(r'regex_pattern')\n",
        "```\n",
        "-.extractall() goes through each text row, looks for everything that matches your pattern, and gives back every match it finds.\n",
        "\n",
        "84. **slice()**\n",
        "\n",
        "```\n",
        "df['column'].str.slice(start, stop)\n",
        "```\n",
        "- It is used to cut a portion (substring) from each string\n",
        "\n",
        "85. **repeat(n)**\n",
        "\n",
        "```\n",
        "df['column'].str.replace(n)\n",
        "```\n",
        "\n",
        "- Repeats each string n no. of times\n",
        "\n",
        "# **Time Series Analysis**\n",
        "\n",
        "Time series analysis is studying data that's recorded over time to find patterns, understand what happened, and predict what might happen next.\n",
        "\n",
        "The main goal is often to forecast the future based on what the past data tells us.\n",
        "\n",
        "Time Series analysis is very important in the financial domain.\n",
        "\n",
        "86. **to_datetime()**\n",
        "\n",
        "```\n",
        "pd.to_datetime(arg, errors='raise', dayfirst=False, format=None, utc=False)\n",
        "```\n",
        "- Converts a wide variety of date/time formats into datetime64 format.\n",
        "\n",
        "87. **date_range()**\n",
        "\n",
        "```\n",
        "pd.date_range(start=None, end=None, periods=None, freq='D', tz=None)\n",
        "start: Start date (string, datetime, or Timestamp)\n",
        "end: End date (same formats)\n",
        "periods: Number of periods to generate\n",
        "freq: Frequency (default is 'D' for daily)\n",
        "tz: Time zone (optional)\n",
        "```\n",
        "- Creates a sequence of datetime values, which is very helpful when generating or simulating time series data.\n",
        "\n",
        "#### **Common Frequencies**\n",
        "\n",
        "| Code             | Frequency   |\n",
        "| ---------------- | ----------- |\n",
        "| `'D'`            | Day         |\n",
        "| `'H'`            | Hour        |\n",
        "| `'T'` or `'min'` | Minute      |\n",
        "| `'S'`            | Second      |\n",
        "| `'M'`            | Month end   |\n",
        "| `'MS'`           | Month start |\n",
        "| `'W'`            | Week        |\n",
        "| `'Q'`            | Quarter end |\n",
        "| `'A'`            | Year end    |\n",
        "\n",
        "88. **DatetimeIndex()**\n",
        "\n",
        "```\n",
        "pd.DatetimeIndex(data=None, freq=None, tz=None, name=None, closed=None, ambiguous='raise', dtype=None, copy=False)\n",
        "\n",
        "data: A list, array, or Series of datetime-like objects (e.g., strings, datetime, or Timestamp)\n",
        "freq: Optional frequency string (e.g., 'D', 'M', 'H')\n",
        "tz: Time zone (e.g., 'UTC', 'America/New_York')\n",
        "name: Optional name for the index\n",
        "copy: Copy data (default False)\n",
        "```\n",
        "- DatetimeIndex converts a list or array of datetime-like values into an index object optimized for time-based operations.\n",
        "\n",
        "89. **resample()**\n",
        "\n",
        "```\n",
        "df.resample(rule, axis=0, closed=None, label=None, convention='start', kind=None, loffset=None, base=None, on=None, level=None, origin='start_day', offset=None)\n",
        "\n",
        "rule: (Required) String representing the frequency (e.g. 'D', 'M', 'W', etc.)\n",
        "axis: Axis to resample on (default is 0, meaning the index)\n",
        "closed: Which side of the bin is closed: 'right' (default) or 'left'\n",
        "label: Where to label the bin: 'right' (default) or 'left'\n",
        "on: For resampling by a column instead of the index\n",
        "level: Use a specific index level for resampling (if multi-index)\n",
        "loffset: Offset to shift labels (deprecated in latest pandas)\n",
        "convention: For upsampling â€” 'start' or 'end' â€” fill values from start or end of the period\n",
        "origin: Defines the timestamp for the start of the bins (e.g. 'epoch', 'start_day')\n",
        "offset: Adjust the resampling bin edges (e.g., '1D' shifts by 1 day)\n",
        "```\n",
        "- Resampling is a process of converting a time series from one frequency to another:\n",
        "\n",
        "  - **Downsampling:** Reducing frequency (e.g., daily â†’ monthly)\n",
        "\n",
        "  - **Upsampling:** Increasing frequency (e.g., monthly â†’ daily)\n",
        "\n",
        "90. **asfreq()**  \n",
        "\n",
        "```\n",
        "df.asfreq(freq, method=None, how=None, normalize=False, fill_value=None)\n",
        "\n",
        "freq: The new frequency (e.g. 'D', 'M', 'H', etc.)\n",
        "method: Optional fill method ('ffill' or 'bfill')\n",
        "fill_value: Value to use for missing values\n",
        "normalize: Whether to reset time to midnight (default False)\n",
        "```\n",
        "- It is used to change the frequency of a time series without aggregating or interpolating values. It's often used for upsampling or downsampling, where you want the data at the new frequency as-is, potentially filling missing values afterward.\n",
        "\n",
        "91. **shift()**\n",
        "\n",
        "```\n",
        "df.shift(periods=1, freq=None, axis=0, fill_value=None)\n",
        "\n",
        "periods: Number of periods to shift (positive = down, negative = up)\n",
        "freq: Optional â€” shift index values by a date/time offset\n",
        "axis: 0 (rows, default) or 1 (columns)\n",
        "fill_value: Value to fill in for introduced missing data\n",
        "```\n",
        "- It is used to shift the values of a DataFrame or Series up or down along the index (usually a DatetimeIndex in time series). It's commonly used to create lag features for time series forecasting or analysis.\n",
        "\n",
        "#### **What is moving window?**\n",
        "A moving window (also called a rolling window) is a fixed-size subset of consecutive data points that \"slides\" through a time series to compute statistics like mean, sum, std, etc., at each step.\n",
        "\n",
        "The window is called moving window because the window slides forward one data point at a time, recalculating the result each time.\n",
        "\n",
        "\n",
        "92. **rolling()**\n",
        "\n",
        "```\n",
        "df.rolling(window, min_periods=None, center=False, win_type=None, axis=0, closed=None)\n",
        "\n",
        "window: Size of the moving window (e.g., 3, '7D', etc.)\n",
        "min_periods: Minimum observations in window to return a result\n",
        "center: If True, center the window label\n",
        "win_type: (Optional) Weighting method (e.g., 'triang', 'gaussian')\n",
        "axis: Axis to apply (default is rows)\n",
        "closed: Controls which sides of window are closed ('right', 'left', 'both', 'neither')\n",
        "```\n",
        "\n",
        "- It is used to perform rolling window operations, such as moving averages, moving sums, rolling standard deviations, etc., over time series data.\n",
        "\n",
        "93. **expanding()**\n",
        "\n",
        "```\n",
        "df.expanding(min_periods=1, axis=0, method='single')\n",
        "\n",
        "min_periods: Minimum number of observations needed to start calculating\n",
        "axis: 0 (rows, default) or 1 (columns)\n",
        "method: Internal optimization (leave as default)\n",
        "```\n",
        "- It is used to compute cumulative statistics (like cumulative mean, sum, etc.) from the start of a time series up to each point.\n",
        "  - It includes all previous data points up to the current one.\n",
        "\n",
        "94. **interpolate()**\n",
        "\n",
        "```\n",
        "df.interpolate(method='linear', axis=0, limit=None, inplace=False, limit_direction='forward', limit_area=None, downcast=None)\n",
        "\n",
        "method: Interpolation technique (see below)\n",
        "axis: 0 = interpolate down rows (default), 1 = across columns\n",
        "limit: Max number of NaNs to fill in a row/column\n",
        "limit_direction: 'forward', 'backward', or 'both'\n",
        "inplace: Modify the original DataFrame if True\n",
        "```\n",
        "\n",
        "| Method                   | Description                                                  |\n",
        "| ------------------------ | ------------------------------------------------------------ |\n",
        "| `'linear'`               | Default. Assumes values change linearly between points       |\n",
        "| `'time'`                 | Use time index for interpolation (must be a `DatetimeIndex`) |\n",
        "| `'polynomial'`           | Use a polynomial function (requires `order=` param)          |\n",
        "| `'spline'`               | Spline interpolation (also needs `order`)                    |\n",
        "| `'pad'` / `'ffill'`      | Fill with last known value                                   |\n",
        "| `'backfill'` / `'bfill'` | Fill with next known value                                   |\n",
        "| `'nearest'`              | Fill with the nearest known value                            |\n",
        "\n",
        "- It is used in pandas to fill in missing values (NaNs) using a variety of interpolation methods. Itâ€™s especially useful in time series data where values change gradually over time (e.g., temperature, stock prices).\n",
        "\n",
        "95. **tz_localize()**\n",
        "\n",
        "```\n",
        "df.tz_localize(tz, axis=0, level=None, copy=True, ambiguous='raise', nonexistent='raise')\n",
        "\n",
        "tz: The time zone to assign (e.g., 'UTC', 'America/New_York')\n",
        "\n",
        "axis: Axis to localize on (default 0, for rows)\n",
        "\n",
        "level: Used for multi-index\n",
        "\n",
        "copy: If False, modify the data in place\n",
        "\n",
        "ambiguous: What to do with ambiguous times (e.g. 'NaT', 'infer')\n",
        "\n",
        "nonexistent: What to do with nonexistent times during DST transition\n",
        "```\n",
        "\n",
        "- This method is used to assign a time zone to a datetime index that currently has no time zone info (naive).\n",
        "\n",
        "96. **tz_convert()**\n",
        "\n",
        "```\n",
        "df.tz_convert(tz, axis=0, level=None, copy=True)\n",
        "\n",
        "tz: The new time zone to convert to (must already have a time zone)\n",
        "\n",
        "axis: Axis to apply on (default 0)\n",
        "\n",
        "level: Used for multi-index with datetime\n",
        "\n",
        "copy: If False, modify in place\n",
        "\n",
        "```\n",
        "\n",
        "- It is used after localization â€” it converts an already localized datetime from one time zone to another.\n",
        "\n",
        "97. **period_range()**\n",
        "\n",
        "```\n",
        "pd.period_range(start=None, end=None, periods=None, freq='D', name=None)\n",
        "\n",
        "start: string or Period-like â€” start period\n",
        "\n",
        "end: string or Period-like â€” end period\n",
        "\n",
        "periods: int â€” number of periods to generate\n",
        "\n",
        "freq: frequency alias (default 'D' for days)\n",
        "\n",
        "name: optional name for the PeriodIndex\n",
        "```\n",
        "\n",
        "- It creates a fixed frequency sequence of Period objects â€” these represent time spans like months, quarters, years, or days, rather than specific timestamps.\n",
        "\n",
        "98. **pct_change()**\n",
        "\n",
        "```\n",
        "Df.pct_change(periods=1, fill_method='pad', limit=None, freq=None, **kwargs)\n",
        "\n",
        "periods: Number of periods to shift for forming the difference (default 1 means compare to previous row).\n",
        "\n",
        "fill_method: How to fill missing values before computing (default 'pad').\n",
        "\n",
        "limit: Maximum number of consecutive NaNs to fill.\n",
        "\n",
        "freq: Frequency to conform before computing percentage change.\n",
        "```\n",
        "\n",
        "-  It computes the percentage change between the current and a prior element in a Series or DataFrame along a given axis.\n",
        "\n",
        "99. **to_timestamp()**\n",
        "\n",
        "```\n",
        "PeriodIndex.to_timestamp(freq=None, how='start')\n",
        "\n",
        "freq: Optional, output frequency alias (e.g., 'D', 'M'). Usually inferred.\n",
        "\n",
        "how: 'start' (default) or 'end' â€” whether to convert to the periodâ€™s start or end timestamp.\n",
        "```\n",
        "- It is used to convert a PeriodIndex or Series of Periods to a TimestampIndex or Series of Timestamps. It turns periods (time spans) into specific points in time (timestamps).\n",
        "\n",
        "100. **diff()**\n",
        "\n",
        "```\n",
        "df.diff(periods=1, axis=0)\n",
        "\n",
        "periods: Number of periods to shift for calculating difference (default is 1, i.e., current row minus previous row).\n",
        "\n",
        "axis: For DataFrame, 0 computes difference row-wise (down the rows), 1 computes difference column-wise (across columns).\n",
        "```\n",
        "\n",
        "- It computes the difference between consecutive elements in a Series or DataFrame. Itâ€™s commonly used to calculate changes or deltas between rows.\n",
        "\n"
      ],
      "metadata": {
        "id": "LRq5OHTrIA69"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DwMIOdIDpHyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sQky_r-2os8I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}